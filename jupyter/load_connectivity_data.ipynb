{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nibabel as nib\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "matplotlib.rcParams['ps.fonttype'] = 42\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os, sys, time\n",
    "import itertools\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/user/pfilipia/home/inria/chu_nice_inria/patients_dmri\"\n",
    "\n",
    "if not 'file_suffix' in globals() and not 'file_suffix' in vars():\n",
    "    file_suffix = None\n",
    "    \n",
    "\n",
    "def get_connections_file(patient_id, file_suffix = None):\n",
    "\n",
    "    if file_suffix is None:\n",
    "        file_suffix = \"_after_shift.csv\"\n",
    "        print(\"File suffix is not defined, using '%s' instead.\" % file_suffix)\n",
    "    \n",
    "    return os.path.join(\n",
    "        data_dir, \n",
    "        \"patient%02d/bids/sub-patient%02d/ses-presurgical/connectivity/connections_common_avg_seed5k%s\" % (\n",
    "            patient_id, patient_id, file_suffix\n",
    "        )\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pd = {}\n",
    "electrode_locations = {}\n",
    "stimulation_site_locations = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_radius_in_spherical_roi(diameter):\n",
    "    radius = diameter / 2\n",
    "    radius_sqr = radius * radius\n",
    "\n",
    "    total_radius = 0\n",
    "    voxels = 0\n",
    "    \n",
    "    for z in np.arange(-radius, radius + 1):\n",
    "        for y in np.arange(-radius, radius + 1):\n",
    "            for x in np.arange(-radius, radius + 1):\n",
    "                \n",
    "                local_radius_sqr = x * x + y * y + z * z\n",
    "                if local_radius_sqr <= radius_sqr:\n",
    "                    total_radius += np.sqrt(local_radius_sqr)\n",
    "                    voxels += 1\n",
    "                    \n",
    "    return total_radius / voxels\n",
    "                    \n",
    "\n",
    "roi_diameter = 10\n",
    "average_radius = average_radius_in_spherical_roi(roi_diameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_electrode_coords(electrode_locations, electrode_id):\n",
    "\n",
    "    if isinstance(electrode_id, str):\n",
    "        electrode_id = int(electrode_id.replace('e', ''))\n",
    "\n",
    "    electrode_coords = np.where(electrode_locations==electrode_id)\n",
    "\n",
    "    return electrode_coords[0][0], electrode_coords[1][0]\n",
    "\n",
    "\n",
    "def get_stimulation_site_coords(electrode_locations, stimulation_site_locations, stimulation_site):\n",
    "\n",
    "    nearest_electrode_coords = get_electrode_coords(\n",
    "        electrode_locations, stimulation_site_locations[stimulation_site][0]\n",
    "    )\n",
    "    x_stim = nearest_electrode_coords[1] - 0.50\n",
    "    y_stim = nearest_electrode_coords[0] + 0.60\n",
    "\n",
    "    shift = 0.5 # 0.75\n",
    "\n",
    "    if 'w' in stimulation_site_locations[stimulation_site][1]:\n",
    "        x_stim -= shift\n",
    "    elif 'e' in stimulation_site_locations[stimulation_site][1]:\n",
    "        x_stim += shift\n",
    "\n",
    "    if 'n' in stimulation_site_locations[stimulation_site][1]:\n",
    "        y_stim -= shift\n",
    "    elif 's' in stimulation_site_locations[stimulation_site][1]:\n",
    "        y_stim += shift\n",
    "\n",
    "    return [x_stim, y_stim]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def show_intensities(data_pd, electrode_locations, stimulation_site_locations):\n",
    "\n",
    "    plot_titles = ['delays', 'amplitudes', 'fibers_num', 'distances']\n",
    "\n",
    "    stimulation_sites = data_pd.iloc[:, 0].unique()\n",
    "    stimulation_sites_num = len(stimulation_sites)\n",
    "\n",
    "    fig, ax = plt.subplots(stimulation_sites_num, 4, figsize=(15, 3 * stimulation_sites_num))\n",
    "\n",
    "    for i in range(stimulation_sites_num):\n",
    "        stimulation_site = stimulation_sites[i]\n",
    "\n",
    "        x = []\n",
    "        y = []\n",
    "\n",
    "        s_latencies = []\n",
    "        s_amplitudes = []\n",
    "        s_fibers_num = []\n",
    "        s_distances = []\n",
    "\n",
    "        for stimulation_record in data_pd[data_pd.iloc[:, 0] == stimulation_site].iterrows():\n",
    "\n",
    "            electrode_coords = get_electrode_coords(electrode_locations, stimulation_record[1][1])\n",
    "\n",
    "            x.append(electrode_coords[1])\n",
    "            y.append(electrode_coords[0])\n",
    "\n",
    "            if stimulation_record[1][10] > 0:\n",
    "                s_latencies.append(stimulation_record[1][10])\n",
    "                s_amplitudes.append(abs(stimulation_record[1][11]))\n",
    "            else:\n",
    "                s_latencies.append(0)\n",
    "                s_amplitudes.append(0)\n",
    "\n",
    "            s_fibers_num.append(stimulation_record[1][3])\n",
    "            s_distances.append(stimulation_record[1][5])\n",
    "\n",
    "        s = np.array([s_latencies, s_amplitudes, s_fibers_num, s_distances])\n",
    "        stim_coords = get_stimulation_site_coords(\n",
    "            electrode_locations, stimulation_site_locations, stimulation_site\n",
    "        )\n",
    "    \n",
    "        for j in range(4):\n",
    "\n",
    "            s_norm = s[j] / np.sum(np.array(s[j]))\n",
    "#             s_norm = s[j] / np.sqrt((np.sum(np.array(s[j])**2)))\n",
    "\n",
    "            ax[i, j].scatter(x, y, s=1, color='black')\n",
    "            ax[i, j].scatter(x, y, s=1000*s_norm)\n",
    "            ax[i, j].text(stim_coords[0], stim_coords[1], '*', fontsize=24, color='magenta')\n",
    "\n",
    "            plt.sca(ax[i, j])\n",
    "            plt.xticks([])\n",
    "            plt.yticks([])\n",
    "            plt.xlim([-1, electrode_locations.shape[1]])\n",
    "            plt.ylim([-1, electrode_locations.shape[0]])\n",
    "\n",
    "            if j == 0:\n",
    "                plt.ylabel(stimulation_site)\n",
    "\n",
    "            plt.gca().invert_yaxis()\n",
    "            plt.title(plot_titles[j])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def binary_value(val):\n",
    "    result = 0\n",
    "    if val > 0:\n",
    "        result = 1\n",
    "    return result\n",
    "\n",
    "def show_connections(data_pd, electrode_locations):\n",
    "\n",
    "    stimulation_sites = data_pd.iloc[:, 0].unique()\n",
    "    stimulation_sites_num = len(stimulation_sites)\n",
    "\n",
    "    count_intersect = 0\n",
    "    count_both = 0\n",
    "    \n",
    "    count_dmri_only = 0\n",
    "    count_des_only = 0\n",
    "    \n",
    "    fig, ax = plt.subplots(stimulation_sites_num, 1, figsize=(5, 4 * stimulation_sites_num))\n",
    "\n",
    "    for i in range(stimulation_sites_num):\n",
    "        stimulation_site = stimulation_sites[i]\n",
    "\n",
    "        x = []\n",
    "        y = []\n",
    "\n",
    "        s_latencies = []\n",
    "        s_fibers_num = []\n",
    "\n",
    "        for stimulation_record in data_pd[data_pd.iloc[:, 0] == stimulation_site].iterrows():\n",
    "\n",
    "            electrode_coords = get_electrode_coords(electrode_locations, stimulation_record[1][1])\n",
    "\n",
    "            x.append(electrode_coords[1])\n",
    "            y.append(electrode_coords[0])\n",
    "\n",
    "            s_latencies.append(binary_value(stimulation_record[1][10]))\n",
    "            s_fibers_num.append(binary_value(stimulation_record[1][3]))\n",
    "\n",
    "        s_fibers_num = np.array(s_fibers_num)\n",
    "        s_latencies = np.array(s_latencies)\n",
    "        \n",
    "        count_intersect = count_intersect + np.sum(s_fibers_num == s_latencies)\n",
    "        count_both      = count_both + np.sum(s_fibers_num + s_latencies > 1)\n",
    "\n",
    "        count_dmri_only = count_dmri_only + np.sum(s_fibers_num > s_latencies)\n",
    "        count_des_only  = count_des_only + np.sum(s_latencies > s_fibers_num)\n",
    "\n",
    "        ax[i].scatter(x, y, s=1, color='black')\n",
    "        ax[i].scatter(x, y, s=100*s_fibers_num, color='black', label='dMRI')\n",
    "        ax[i].scatter(x, y, s=200*s_latencies, marker='x', color='red', label='DES')\n",
    "\n",
    "        plt.sca(ax[i])\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.xlim([-1, electrode_locations.shape[1]])\n",
    "        plt.ylim([-1, electrode_locations.shape[0]])\n",
    "\n",
    "        plt.ylabel(stimulation_site)\n",
    "\n",
    "        plt.gca().invert_yaxis()\n",
    "        plt.title(\"connections dMRI vs. DES\")\n",
    "        plt.legend()\n",
    "\n",
    "    total_count = count_intersect + count_dmri_only + count_des_only\n",
    "    print(\"dMRI = DES: %3d (%3d%%)\" % (count_intersect, 100 * count_intersect / total_count))\n",
    "    print(\"dMRI & DES: %3d (%3d%%)\\n\" % (count_both, 100 * count_both / total_count))\n",
    "    print(\"dMRI only : %3d (%3d%%)\" % (count_dmri_only, 100 * count_dmri_only / total_count))\n",
    "    print(\"DES only  : %3d (%3d%%)\" % (count_des_only, 100 * count_des_only / total_count))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate_electrode_locations(electrode_locations):\n",
    "    \n",
    "    return np.flipud(np.fliplr(electrode_locations))\n",
    "\n",
    "\n",
    "def rotate_stimulation_site_locations(stimulation_site_locations):\n",
    "    \n",
    "    direction_mapping = {\n",
    "        'n': 's', 'e': 'w', 's': 'n', 'w': 'e',\n",
    "        'ne': 'sw', 'nw': 'se', 'se': 'nw', 'sw': 'ne'\n",
    "    }\n",
    "    \n",
    "    for stimulation_site in stimulation_site_locations:\n",
    "        \n",
    "        stimulation_site_locations[stimulation_site][1] = direction_mapping[stimulation_site_locations[stimulation_site][1]]\n",
    "        \n",
    "    return stimulation_site_locations\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Patient #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File suffix is not defined, using '_after_shift.csv' instead.\n"
     ]
    }
   ],
   "source": [
    "patient_id = 1 \n",
    "\n",
    "electrode_locations[patient_id] = rotate_electrode_locations(np.array([\n",
    "    [ 1,  5,  0,  0,  0,  0,  0,  0],\n",
    "    [ 2,  6,  0,  0,  0,  0,  0,  0],\n",
    "    [ 3,  7,  0,  0,  0,  0,  0,  0],\n",
    "    [ 4,  8,  0,  0,  0,  0,  0,  0],\n",
    "    [ 0,  0, 14, 13, 12, 11, 10,  9]\n",
    "]))\n",
    "\n",
    "stimulation_site_locations[patient_id] = rotate_stimulation_site_locations({\n",
    "    's00': [  1,  'w' ],\n",
    "    's01': [  2, 'sw' ],\n",
    "    's02': [  4,  'w' ],\n",
    "    's03': [  6,  'e' ],\n",
    "    's04': [  7,  'e' ],\n",
    "    's05': [  8, 'se' ],\n",
    "    's06': [  5, 'ne' ],\n",
    "    's07': [ 13,  'n' ],\n",
    "    's08': [ 12,  'n' ],\n",
    "    's09': [  1,  'n' ]\n",
    "})\n",
    "\n",
    "try:\n",
    "    data_pd[patient_id] = pd.read_csv(get_connections_file(patient_id, file_suffix), skipinitialspace=True)\n",
    "except:\n",
    "    print(\"Couldn't load Patient #%d data using file suffix: %s\" % (patient_id, file_suffix))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Patient #3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File suffix is not defined, using '_after_shift.csv' instead.\n"
     ]
    }
   ],
   "source": [
    "patient_id = 3\n",
    "\n",
    "electrode_locations[patient_id] = np.array([\n",
    "    [ 1,  0,  0,  0,  0,  0 ],\n",
    "    [ 2,  0,  0,  0,  0,  0 ],\n",
    "    [ 3,  0,  0,  0,  0,  0 ],\n",
    "    [ 4,  0,  0,  0,  0,  0 ],\n",
    "    [ 0,  0,  0,  0,  0,  0 ],\n",
    "    [ 5,  6,  7,  8,  9, 10 ]\n",
    "])\n",
    "\n",
    "stimulation_site_locations[patient_id] = {\n",
    "    's00': [  1,  'e' ],\n",
    "    's01': [  2,  'e' ],\n",
    "    's02': [  3,  'e' ],\n",
    "    's03': [  4, 'se' ],\n",
    "    's04': [  6,  's' ],\n",
    "    's05': [  7,  's' ],\n",
    "    's06': [  8,  's' ],\n",
    "    's07': [  9,  's' ],\n",
    "    's08': [ 10,  's' ],\n",
    "    's09': [  9,  'n' ]\n",
    "}\n",
    "\n",
    "try:\n",
    "    data_pd[patient_id] = pd.read_csv(get_connections_file(patient_id, file_suffix), skipinitialspace=True)\n",
    "except:\n",
    "    print(\"Couldn't load Patient #%d data using file suffix: %s\" % (patient_id, file_suffix))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Patient #4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File suffix is not defined, using '_after_shift.csv' instead.\n"
     ]
    }
   ],
   "source": [
    "patient_id = 4\n",
    "\n",
    "electrode_locations[patient_id] = np.array([\n",
    "    [  0,  0,  0,  0,  0,  9,  0,  0 ],\n",
    "    [  0,  0,  0,  0, 10,  0,  0,  0 ],\n",
    "    [  0,  0,  0, 11,  0,  0,  0,  0 ],\n",
    "    [  0,  0, 12,  0,  0,  0,  0,  0 ],\n",
    "    [  0, 13,  0,  0,  0,  0,  0,  0 ],\n",
    "    [ 14,  0,  0,  0,  4,  3,  2,  1 ],\n",
    "    [  0,  0,  0,  0,  8,  7,  6,  5 ]\n",
    "])\n",
    "\n",
    "stimulation_site_locations[patient_id] = {\n",
    "    's00': [  9, 'se' ],\n",
    "    's01': [ 10, 'se' ],\n",
    "    's02': [ 11, 'se' ],\n",
    "    's03': [ 12, 'se' ],\n",
    "    's04': [ 13, 'se' ],\n",
    "    's05': [ 14, 'se' ],\n",
    "    's06': [  1,  'n' ],\n",
    "    's07': [  2,  'n' ],\n",
    "    's08': [  3,  'n' ],\n",
    "    's09': [  4,  'n' ],\n",
    "    's10': [  5,  's' ],\n",
    "    's11': [  6,  's' ],\n",
    "    's12': [  7, 'sw' ],\n",
    "    's13': [  8, 'nw' ]    \n",
    "}\n",
    "\n",
    "try:\n",
    "    data_pd[patient_id] = pd.read_csv(get_connections_file(patient_id, file_suffix), skipinitialspace=True)\n",
    "except:\n",
    "    print(\"Couldn't load Patient #%d data using file suffix: %s\" % (patient_id, file_suffix))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Patient #6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File suffix is not defined, using '_after_shift.csv' instead.\n"
     ]
    }
   ],
   "source": [
    "patient_id = 6\n",
    "\n",
    "electrode_locations[patient_id] = np.array([\n",
    "    [  0,  0,  0,  8,  4,  0 ],\n",
    "    [  0,  0,  0,  7,  3,  0 ],\n",
    "    [  0,  0,  0,  6,  2,  0 ],\n",
    "    [  0,  0,  0,  5,  1,  0 ],\n",
    "    [ 14, 13, 12, 11, 10,  9 ]\n",
    "])\n",
    "\n",
    "stimulation_site_locations[patient_id] = {\n",
    "    's01': [  5,  'w' ],\n",
    "    's02': [ 13,  'n' ],\n",
    "    's03': [ 14, 'nw' ],\n",
    "    's04': [  2,  'e' ],\n",
    "    's05': [  3,  'e' ],\n",
    "    's06': [  4,  'e' ],\n",
    "    's07': [  8,  'w' ],\n",
    "    's08': [  7,  'w' ],\n",
    "    's09': [  6,  'w' ]\n",
    "}\n",
    "\n",
    "try:\n",
    "    data_pd[patient_id] = pd.read_csv(get_connections_file(patient_id, file_suffix), skipinitialspace=True)\n",
    "except:\n",
    "    print(\"Couldn't load Patient #%d data using file suffix: %s\" % (patient_id, file_suffix))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Patient #7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File suffix is not defined, using '_after_shift.csv' instead.\n"
     ]
    }
   ],
   "source": [
    "patient_id = 7\n",
    "\n",
    "# electrode_locations[patient_id] = np.array([\n",
    "#     [  9, 10, 11,  0,  0,  0 ],\n",
    "#     [  0,  0,  0, 12, 13, 14 ],\n",
    "#     [  0,  0,  0,  0,  0,  0 ],\n",
    "#     [  0,  5,  6,  7,  8,  0 ],\n",
    "#     [  0,  1,  2,  3,  4,  0 ]\n",
    "# ])\n",
    "\n",
    "electrode_locations[patient_id] = np.array([\n",
    "    [  9, 10, 11, 12, 13, 14 ],\n",
    "    [  0,  0,  0,  0,  0,  0 ],\n",
    "    [  0,  5,  6,  7,  8,  0 ],\n",
    "    [  0,  1,  2,  3,  4,  0 ]\n",
    "])\n",
    "\n",
    "stimulation_site_locations[patient_id] = {\n",
    "    's00': [ 14,  's' ],\n",
    "    's01': [  1, 'se' ],\n",
    "    's02': [  2,  's' ],\n",
    "    's03': [  3,  's' ],\n",
    "    's04': [  4,  's' ],\n",
    "    's05': [  5, 'ne' ],\n",
    "    's06': [  6,  'n' ],\n",
    "    's07': [  7,  'n' ],\n",
    "    's08': [  8,  'n' ],\n",
    "    's09': [ 12,  's' ],\n",
    "    's10': [ 13,  's' ]\n",
    "}\n",
    "\n",
    "try:\n",
    "    data_pd[patient_id] = pd.read_csv(get_connections_file(patient_id, file_suffix), skipinitialspace=True)\n",
    "except:\n",
    "    print(\"Couldn't load Patient #%d data using file suffix: %s\" % (patient_id, file_suffix))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Patient #8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File suffix is not defined, using '_after_shift.csv' instead.\n"
     ]
    }
   ],
   "source": [
    "patient_id = 8\n",
    "\n",
    "electrode_locations[patient_id] = np.array([\n",
    "    [  0,  0,  0,  0,  0,  0 ],\n",
    "    [  0,  4,  3,  2,  1,  0 ],\n",
    "    [  0,  8,  7,  6,  5,  0 ],\n",
    "    [  0,  0,  0,  0,  0,  0 ]\n",
    "])\n",
    "\n",
    "stimulation_site_locations[patient_id] = {\n",
    "    's00': [  1,  'n' ],\n",
    "    's01': [  2,  'n' ],\n",
    "    's02': [  3,  'n' ],\n",
    "    's03': [  4,  'n' ],\n",
    "    's04': [  5,  's' ],\n",
    "    's05': [  6,  's' ],\n",
    "    's06': [  7,  's' ],\n",
    "    's07': [  8,  's' ],\n",
    "}\n",
    "\n",
    "try:\n",
    "    data_pd[patient_id] = pd.read_csv(get_connections_file(patient_id, file_suffix), skipinitialspace=True)\n",
    "except:\n",
    "    print(\"Couldn't load Patient #%d data using file suffix: %s\" % (patient_id, file_suffix))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Patient #10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File suffix is not defined, using '_after_shift.csv' instead.\n"
     ]
    }
   ],
   "source": [
    "patient_id = 10\n",
    "\n",
    "electrode_locations[patient_id] = rotate_electrode_locations(np.array([\n",
    "    [ 8,  4,  0,  0,  0,  0,  0,  0],\n",
    "    [ 7,  3,  0,  0,  0,  0,  0,  0],\n",
    "    [ 6,  2,  0,  0,  0,  0,  0,  0],\n",
    "    [ 5,  1,  0,  0,  0,  0,  0,  0],\n",
    "    [ 0,  0, 14, 13, 12, 11, 10,  9]\n",
    "]))\n",
    "\n",
    "stimulation_site_locations[patient_id] = rotate_stimulation_site_locations({\n",
    "    's01': [  9,  's' ],\n",
    "    's02': [ 10,  's' ],\n",
    "    's03': [ 11,  's' ],\n",
    "    's04': [ 12,  'n' ],\n",
    "    's05': [ 13,  's' ],\n",
    "    's06': [ 14,  's' ],\n",
    "    's07': [  1,  'e' ],\n",
    "    's08': [  2,  'e' ],\n",
    "    's09': [  3,  'e' ],\n",
    "    's10': [  4,  'e' ]\n",
    "})\n",
    "\n",
    "try:\n",
    "    data_pd[patient_id] = pd.read_csv(get_connections_file(patient_id, file_suffix), skipinitialspace=True)\n",
    "except:\n",
    "    print(\"Couldn't load Patient #%d data using file suffix: %s\" % (patient_id, file_suffix))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Patient #11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File suffix is not defined, using '_after_shift.csv' instead.\n"
     ]
    }
   ],
   "source": [
    "patient_id = 11\n",
    "\n",
    "electrode_locations[patient_id] = rotate_electrode_locations(np.array([\n",
    "    [ 8,  4,  0,  0,  0,  0,  0],\n",
    "    [ 7,  3,  0,  0,  0,  0,  0],\n",
    "    [ 6,  2,  0,  0,  0,  0,  0],\n",
    "    [ 5,  1,  0,  0,  0,  0,  0],\n",
    "    [ 0, 14, 13, 12, 11, 10,  9]\n",
    "]))\n",
    "\n",
    "stimulation_site_locations[patient_id] = rotate_stimulation_site_locations({\n",
    "    's01': [  9,  'n' ],\n",
    "    's02': [ 10,  'n' ],\n",
    "    's03': [ 11,  's' ],\n",
    "    's04': [ 12,  's' ],\n",
    "    's05': [ 13,  's' ],\n",
    "    's06': [ 14,  's' ],\n",
    "    's07': [  1, 'ne' ],\n",
    "    's08': [  2,  'e' ],\n",
    "    's09': [  3,  'e' ],\n",
    "    's10': [  4,  'e' ],\n",
    "    's11': [  8,  'w' ],\n",
    "    's12': [  6,  'w' ]\n",
    "})\n",
    "\n",
    "try:\n",
    "    data_pd[patient_id] = pd.read_csv(get_connections_file(patient_id, file_suffix), skipinitialspace=True)\n",
    "except:\n",
    "    print(\"Couldn't load Patient #%d data using file suffix: %s\" % (patient_id, file_suffix))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Patient #12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File suffix is not defined, using '_after_shift.csv' instead.\n"
     ]
    }
   ],
   "source": [
    "patient_id = 12\n",
    "\n",
    "electrode_locations[patient_id] = rotate_electrode_locations(np.array([\n",
    "    [ 0,  9,  0,  0,  0],\n",
    "    [ 0, 10,  5,  1,  0],\n",
    "    [ 0, 11,  6,  2,  0],\n",
    "    [ 0, 12,  7,  3,  0],\n",
    "    [ 0, 13,  8,  4,  0],\n",
    "    [ 0, 14,  0,  0,  0]\n",
    "]))\n",
    "\n",
    "stimulation_site_locations[patient_id] = rotate_stimulation_site_locations({\n",
    "    's01': [  1,  'e' ],\n",
    "    's02': [  2,  'e' ],\n",
    "    's03': [  3,  'e' ],\n",
    "    's04': [  4,  'e' ],\n",
    "    's05': [  5,  'e' ],\n",
    "    's06': [  6,  'e' ],\n",
    "    's07': [  7,  'e' ],\n",
    "    's08': [  8,  'e' ],\n",
    "    's09': [ 10,  'e' ],\n",
    "    's10': [ 11,  'e' ],\n",
    "    's11': [ 12,  'e' ],\n",
    "    's12': [ 13,  'e' ]\n",
    "})\n",
    "\n",
    "try:\n",
    "    data_pd[patient_id] = pd.read_csv(get_connections_file(patient_id, file_suffix), skipinitialspace=True)\n",
    "except:\n",
    "    print(\"Couldn't load Patient #%d data using file suffix: %s\" % (patient_id, file_suffix))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_labels = {\n",
    "     1 : 1,\n",
    "     3 : 2,\n",
    "     4 : 3,\n",
    "     6 : 4,\n",
    "     7 : 5,\n",
    "     8 : 6,\n",
    "    10 : 7,\n",
    "    11 : 8,\n",
    "    12 : 9\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_connections_data(data_pd, column_id):\n",
    "    \n",
    "    stimulation_sites = sorted(data_pd.iloc[:, 0].unique())\n",
    "    stimulation_sites_num = len(stimulation_sites)\n",
    "\n",
    "    electrodes = sorted(data_pd.iloc[:, 1].unique())\n",
    "    electrodes_num = len(electrodes)\n",
    "\n",
    "    result_matrix = np.zeros([stimulation_sites_num, electrodes_num])\n",
    "    \n",
    "    for stimulation_record in data_pd.iterrows():\n",
    "        try:\n",
    "            row_id = stimulation_sites.index(stimulation_record[1][0])\n",
    "            col_id = electrodes.index(stimulation_record[1][1])\n",
    "            value = stimulation_record[1][column_id]\n",
    "            if not np.isnan(value):\n",
    "                result_matrix[row_id, col_id] = value\n",
    "        except:\n",
    "            None\n",
    "            \n",
    "    return result_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_streamlines_count_matrix(data_pd):\n",
    "\n",
    "    return fetch_connections_data(data_pd, 3)\n",
    "\n",
    "\n",
    "def get_streamlines_log_count_matrix(data_pd):\n",
    "\n",
    "    return np.log10(1 + get_streamlines_count_matrix(data_pd))\n",
    "\n",
    "\n",
    "def get_streamlines_min_length_matrix(data_pd):\n",
    "\n",
    "    return 2 * average_radius + fetch_connections_data(data_pd, 5)\n",
    "\n",
    "\n",
    "def get_streamlines_sqrt_min_length_matrix(data_pd):\n",
    "\n",
    "    return np.sqrt(2 * average_radius + fetch_connections_data(data_pd, 5))\n",
    "\n",
    "\n",
    "def get_streamlines_log_min_length_matrix(data_pd):\n",
    "    \n",
    "    return np.log10(1 + get_streamlines_min_length_matrix(data_pd))\n",
    "\n",
    "\n",
    "def get_streamlines_max_length_matrix(data_pd):\n",
    "\n",
    "    return 2 * average_radius + fetch_connections_data(data_pd, 6)\n",
    "\n",
    "\n",
    "def get_streamlines_avg_length_matrix(data_pd):\n",
    "\n",
    "    return 2 * average_radius + fetch_connections_data(data_pd, 7)\n",
    "\n",
    "\n",
    "def get_streamlines_median_length_matrix(data_pd):\n",
    "\n",
    "    return 2 * average_radius + fetch_connections_data(data_pd, 8)\n",
    "\n",
    "\n",
    "def get_streamlines_std_length_matrix(data_pd):\n",
    "\n",
    "    return fetch_connections_data(data_pd, 9)\n",
    "\n",
    "\n",
    "def get_evoked_potential_delay_matrix(data_pd):\n",
    "    \n",
    "    return fetch_connections_data(data_pd, 10)\n",
    "\n",
    "\n",
    "def get_evoked_potential_amplitude_matrix(data_pd):\n",
    "    \n",
    "    return np.abs(fetch_connections_data(data_pd, 11))\n",
    "\n",
    "\n",
    "def get_smoothwm_surface_distance_matrix(data_pd):\n",
    "\n",
    "    return fetch_connections_data(data_pd, 14)\n",
    "\n",
    "\n",
    "def get_pial_surface_distance_matrix(data_pd):\n",
    "\n",
    "    return fetch_connections_data(data_pd, 15)\n",
    "\n",
    "\n",
    "def get_trk_streamlines_count_matrix(data_pd):\n",
    "\n",
    "    return fetch_connections_data(data_pd, 16)\n",
    "\n",
    "\n",
    "def get_trk_streamlines_min_length_matrix(data_pd):\n",
    "\n",
    "    return 2 * average_radius + fetch_connections_data(data_pd, 17)\n",
    "\n",
    "\n",
    "def get_trk_streamlines_10_length_matrix(data_pd):\n",
    "\n",
    "    return 2 * average_radius + fetch_connections_data(data_pd, 18)\n",
    "\n",
    "\n",
    "def get_trk_streamlines_20_length_matrix(data_pd):\n",
    "\n",
    "    return 2 * average_radius + fetch_connections_data(data_pd, 19)\n",
    "\n",
    "\n",
    "def get_trk_streamlines_30_length_matrix(data_pd):\n",
    "\n",
    "    return 2 * average_radius + fetch_connections_data(data_pd, 20)\n",
    "\n",
    "\n",
    "def get_trk_streamlines_40_length_matrix(data_pd):\n",
    "\n",
    "    return 2 * average_radius + fetch_connections_data(data_pd, 21)\n",
    "\n",
    "\n",
    "def get_trk_streamlines_median_length_matrix(data_pd):\n",
    "\n",
    "    return 2 * average_radius + fetch_connections_data(data_pd, 22)\n",
    "\n",
    "\n",
    "def get_trk_streamlines_max_length_matrix(data_pd):\n",
    "\n",
    "    return 2 * average_radius + fetch_connections_data(data_pd, 23)\n",
    "\n",
    "\n",
    "def get_mean_fa_matrix(data_pd):\n",
    "\n",
    "    return fetch_connections_data(data_pd, 24)\n",
    "\n",
    "\n",
    "def get_mean_md_matrix(data_pd):\n",
    "\n",
    "    return fetch_connections_data(data_pd, 26)\n",
    "\n",
    "\n",
    "def get_mean_ad_matrix(data_pd):\n",
    "\n",
    "    return fetch_connections_data(data_pd, 28)\n",
    "\n",
    "\n",
    "def get_mean_rd_matrix(data_pd):\n",
    "\n",
    "    return fetch_connections_data(data_pd, 30)\n",
    "\n",
    "\n",
    "def get_mean_rtop_matrix(data_pd):\n",
    "\n",
    "    return np.power(np.maximum(0, fetch_connections_data(data_pd, 32)), 1.0/3)\n",
    "\n",
    "\n",
    "def get_mean_rtap_matrix(data_pd):\n",
    "\n",
    "    return np.power(np.maximum(0, fetch_connections_data(data_pd, 33)), 1.0/2)\n",
    "\n",
    "\n",
    "def get_mean_rtpp_matrix(data_pd):\n",
    "\n",
    "    return np.maximum(0, fetch_connections_data(data_pd, 34))\n",
    "\n",
    "\n",
    "def get_mean_msd_matrix(data_pd):\n",
    "\n",
    "    return np.maximum(0, fetch_connections_data(data_pd, 35))\n",
    "\n",
    "\n",
    "def get_mean_qiv_matrix(data_pd):\n",
    "\n",
    "    return np.maximum(0, fetch_connections_data(data_pd, 36))\n",
    "\n",
    "\n",
    "def get_mean_ng_matrix(data_pd):\n",
    "\n",
    "    return np.maximum(0, fetch_connections_data(data_pd, 37))\n",
    "\n",
    "\n",
    "def get_mean_ng_perp_matrix(data_pd):\n",
    "\n",
    "    return np.maximum(0, fetch_connections_data(data_pd, 38))\n",
    "\n",
    "\n",
    "def get_mean_ng_par_matrix(data_pd):\n",
    "\n",
    "    return np.maximum(0, fetch_connections_data(data_pd, 39))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inversed_streamlines_count_matrix(data_pd):\n",
    "\n",
    "    return 1.0 / (1.0 + get_streamlines_count_matrix(data_pd))\n",
    "\n",
    "\n",
    "def get_inversed_streamlines_log_count_matrix(data_pd):\n",
    "\n",
    "    return 1.0 / (1.0 + get_streamlines_log_count_matrix(data_pd))\n",
    "\n",
    "\n",
    "def get_inversed_length_based_matrix(data_pd, callback_fun):\n",
    "\n",
    "    return 1.0 / (1.0 + callback_fun(data_pd))\n",
    "\n",
    "\n",
    "def get_inversed_streamlines_min_length_matrix(data_pd):\n",
    "\n",
    "    return get_inversed_length_based_matrix(data_pd, get_streamlines_min_length_matrix)\n",
    "\n",
    "\n",
    "def get_inversed_streamlines_max_length_matrix(data_pd):\n",
    "\n",
    "    return get_inversed_length_based_matrix(data_pd, get_streamlines_max_length_matrix)\n",
    "\n",
    "\n",
    "def get_inversed_streamlines_avg_length_matrix(data_pd):\n",
    "\n",
    "    return get_inversed_length_based_matrix(data_pd, get_streamlines_avg_length_matrix)\n",
    "\n",
    "\n",
    "def get_inversed_streamlines_median_length_matrix(data_pd):\n",
    "\n",
    "    return get_inversed_length_based_matrix(data_pd, get_streamlines_median_length_matrix)\n",
    "\n",
    "\n",
    "def get_inversed_streamlines_std_length_matrix(data_pd):\n",
    "\n",
    "    return get_inversed_length_based_matrix(data_pd, get_streamlines_std_length_matrix)\n",
    "\n",
    "\n",
    "def get_inversed_smoothwm_surface_distance_matrix(data_pd):\n",
    "\n",
    "    return get_inversed_length_based_matrix(data_pd, get_smoothwm_surface_distance_matrix)\n",
    "\n",
    "\n",
    "def get_inversed_pial_surface_distance_matrix(data_pd):\n",
    "\n",
    "    return get_inversed_length_based_matrix(data_pd, get_pial_surface_distance_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_count_based_connectivity_matrix(data_pd, mask = None):\n",
    "       \n",
    "    result_matrix = get_streamlines_count_matrix(data_pd)\n",
    "    if not mask is None:\n",
    "        result_matrix[np.logical_not(mask)] = 0\n",
    "    return result_matrix / np.sum(result_matrix)\n",
    "\n",
    "def get_log_count_based_connectivity_matrix(data_pd, mask = None):\n",
    "       \n",
    "    result_matrix = get_streamlines_log_count_matrix(data_pd)\n",
    "    if not mask is None:\n",
    "        result_matrix[np.logical_not(mask)] = 0\n",
    "    return result_matrix / np.sum(result_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fractionally_scalled_connectivity_matrix(data_pd, mask = None):\n",
    "\n",
    "    input_matrix = get_streamlines_count_matrix(data_pd)\n",
    "    result_matrix = np.zeros_like(input_matrix)\n",
    "\n",
    "    for row_id in range(input_matrix.shape[0]):\n",
    "        for col_id in range(input_matrix.shape[1]):\n",
    "            scaling_factor = np.sum(input_matrix[row_id, :col_id])\n",
    "            scaling_factor += np.sum(input_matrix[row_id, col_id+1:])\n",
    "            scaling_factor += np.sum(input_matrix[:row_id, col_id])\n",
    "            scaling_factor += np.sum(input_matrix[row_id+1:, col_id])\n",
    "            result_matrix[row_id, col_id] = input_matrix[row_id, col_id] / scaling_factor\n",
    "    \n",
    "    if not mask is None:\n",
    "        result_matrix[np.logical_not(mask)] = 0\n",
    "    \n",
    "    return result_matrix / np.sum(result_matrix)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_length_based_connectivity_matrix(data_pd, callback_fun, mask = None, distance_threshold = None):\n",
    "       \n",
    "    result_matrix = callback_fun(data_pd)\n",
    "    \n",
    "    if distance_threshold:\n",
    "        result_matrix[result_matrix > distance_threshold] = 0\n",
    "    \n",
    "    if not mask is None:\n",
    "        result_matrix[np.logical_not(mask)] = 0\n",
    "    \n",
    "    return result_matrix / np.sum(result_matrix)\n",
    "    \n",
    "\n",
    "def get_streamlines_min_length_based_connectivity_matrix(data_pd, mask = None, distance_threshold = None):\n",
    "\n",
    "    return get_length_based_connectivity_matrix(\n",
    "        data_pd, get_streamlines_min_length_matrix, mask, distance_threshold\n",
    "    )\n",
    "\n",
    "\n",
    "def get_streamlines_max_length_based_connectivity_matrix(data_pd, mask = None, distance_threshold = None):\n",
    "\n",
    "    return get_length_based_connectivity_matrix(\n",
    "        data_pd, get_streamlines_max_length_matrix, mask, distance_threshold\n",
    "    )\n",
    "\n",
    "\n",
    "def get_streamlines_avg_length_based_connectivity_matrix(data_pd, mask = None, distance_threshold = None):\n",
    "\n",
    "    return get_length_based_connectivity_matrix(\n",
    "        data_pd, get_streamlines_avg_length_matrix, mask, distance_threshold\n",
    "    )\n",
    "\n",
    "\n",
    "def get_streamlines_std_length_based_connectivity_matrix(data_pd, mask = None, distance_threshold = None):\n",
    "\n",
    "    return get_length_based_connectivity_matrix(\n",
    "        data_pd, get_streamlines_std_length_matrix, mask, distance_threshold\n",
    "    )\n",
    "\n",
    "\n",
    "def get_smoothwm_surface_distance_based_connectivity_matrix(data_pd, mask = None, distance_threshold = None):\n",
    "\n",
    "    return get_length_based_connectivity_matrix(\n",
    "        data_pd, get_smoothwm_surface_distance_matrix, mask, distance_threshold\n",
    "    )\n",
    "\n",
    "\n",
    "def get_pial_surface_distance_based_connectivity_matrix(data_pd, mask = None, distance_threshold = None):\n",
    "\n",
    "    return get_length_based_connectivity_matrix(\n",
    "        data_pd, get_pial_surface_distance_matrix, mask, distance_threshold\n",
    "    )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inversed_length_based_connectivity_matrix(data_pd, callback_fun, mask = None):\n",
    "    \n",
    "    result_matrix = 1 / (1 + callback_fun(data_pd))\n",
    "\n",
    "    if not mask is None:\n",
    "        result_matrix[np.logical_not(mask)] = 0\n",
    "    \n",
    "    return result_matrix / np.sum(result_matrix)\n",
    "\n",
    "\n",
    "def get_inversed_streamlines_min_length_based_connectivity_matrix(data_pd, mask = None):\n",
    "\n",
    "    return get_inversed_length_based_connectivity_matrix(\n",
    "        data_pd, get_streamlines_min_length_matrix, mask\n",
    "    )\n",
    "\n",
    "\n",
    "def get_inversed_streamlines_max_length_based_connectivity_matrix(data_pd, mask = None, distance_threshold = None):\n",
    "\n",
    "    return get_inversed_length_based_connectivity_matrix(\n",
    "        data_pd, get_streamlines_max_length_matrix, mask\n",
    "    )\n",
    "\n",
    "\n",
    "def get_inversed_streamlines_avg_length_based_connectivity_matrix(data_pd, mask = None, distance_threshold = None):\n",
    "\n",
    "    return get_inversed_length_based_connectivity_matrix(\n",
    "        data_pd, get_streamlines_avg_length_matrix, mask\n",
    "    )\n",
    "\n",
    "\n",
    "def get_inversed_streamlines_std_length_based_connectivity_matrix(data_pd, mask = None, distance_threshold = None):\n",
    "\n",
    "    return get_inversed_length_based_connectivity_matrix(\n",
    "        data_pd, get_streamlines_std_length_matrix, mask\n",
    "    )\n",
    "\n",
    "\n",
    "def get_inversed_smoothwm_surface_distance_based_connectivity_matrix(data_pd, mask = None, distance_threshold = None):\n",
    "\n",
    "    return get_inversed_length_based_connectivity_matrix(\n",
    "        data_pd, get_smoothwm_surface_distance_matrix, mask\n",
    "    )\n",
    "\n",
    "\n",
    "def get_inversed_pial_surface_distance_based_connectivity_matrix(data_pd, mask = None, distance_threshold = None):\n",
    "\n",
    "    return get_inversed_length_based_connectivity_matrix(\n",
    "        data_pd, get_pial_surface_distance_matrix, mask\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_delay_based_connectivity_matrix(data_pd, mask = None):\n",
    "    \n",
    "    result_matrix = get_evoked_potential_delay_matrix(data_pd)\n",
    "    result_matrix[result_matrix > 0] -= np.min(result_matrix[result_matrix > 0]) - 1\n",
    "    \n",
    "    if not mask is None:\n",
    "        result_matrix[np.logical_not(mask)] = 0\n",
    "    \n",
    "    return result_matrix / np.sum(result_matrix)\n",
    "\n",
    "\n",
    "def get_inversed_delay_based_connectivity_matrix(data_pd, mask = None):\n",
    "    \n",
    "    result_matrix = 1 / (1 + get_evoked_potential_delay_matrix(data_pd))\n",
    "    \n",
    "    if not mask is None:\n",
    "        result_matrix[np.logical_not(mask)] = 0\n",
    "    \n",
    "    return result_matrix / np.sum(result_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_amplitude_based_connectivity_matrix(data_pd, mask = None):\n",
    "    \n",
    "    result_matrix = get_evoked_potential_amplitude_matrix(data_pd)\n",
    "    \n",
    "    if not mask is None:\n",
    "        result_matrix[np.logical_not(mask)] = 0\n",
    "    \n",
    "    return result_matrix / np.sum(result_matrix)\n",
    "\n",
    "\n",
    "def get_inversed_amplitude_based_connectivity_matrix(data_pd, mask = None):\n",
    "    \n",
    "    result_matrix = 1 / (1 + get_evoked_potential_amplitude_matrix(data_pd))\n",
    "    \n",
    "    if not mask is None:\n",
    "        result_matrix[np.logical_not(mask)] = 0\n",
    "    \n",
    "    return result_matrix / np.sum(result_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_intraelectrode_distance_matrix(electrode_locations, stimulation_site_locations):\n",
    "    \n",
    "    stimulation_sites = sorted(stimulation_site_locations)\n",
    "    stimulation_sites_num = len(stimulation_sites)\n",
    "\n",
    "    electrodes = sorted(electrode_locations[electrode_locations > 0])\n",
    "    electrodes_num = len(electrodes)\n",
    "\n",
    "    result_matrix = np.zeros([stimulation_sites_num, electrodes_num])\n",
    "    \n",
    "    for stimulation_site_id in stimulation_sites:\n",
    "        row_id = stimulation_sites.index(stimulation_site_id)\n",
    "\n",
    "        for electrode_id in electrodes:\n",
    "            col_id = electrodes.index(electrode_id)\n",
    "            \n",
    "            stimulation_site_coords = np.array(get_electrode_coords(\n",
    "                electrode_locations, stimulation_site_locations[stimulation_site_id][0]\n",
    "            ), dtype=float)\n",
    "            \n",
    "            shift = 0.5\n",
    "\n",
    "            if 'w' in stimulation_site_locations[stimulation_site_id][1]:\n",
    "                stimulation_site_coords[0] -= shift\n",
    "            elif 'e' in stimulation_site_locations[stimulation_site_id][1]:\n",
    "                stimulation_site_coords[0] += shift\n",
    "\n",
    "            if 'n' in stimulation_site_locations[stimulation_site_id][1]:\n",
    "                stimulation_site_coords[1] -= shift\n",
    "            elif 's' in stimulation_site_locations[stimulation_site_id][1]:\n",
    "                stimulation_site_coords[1] += shift\n",
    "\n",
    "            electrode_coords = np.array(get_electrode_coords(electrode_locations, electrode_id))\n",
    "            result_matrix[row_id, col_id] = np.sqrt(np.sum((stimulation_site_coords - electrode_coords) ** 2))\n",
    "            \n",
    "    return result_matrix\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
